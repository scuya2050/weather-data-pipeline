{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e45bb0e3-c0b6-4123-9eb6-550367e8b46e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79ba8858-5008-45fb-a0c9-bafa9ab10b2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import schema_of_json, current_timestamp, input_file_name, lit, col, to_json, from_json, to_timestamp, to_utc_timestamp, window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DoubleType, LongType, BooleanType\n",
    "import pyspark.sql.functions as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "586c4a67-d311-4f5e-9d3e-c89442738a4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d956e63-36bf-41fe-8714-2a5fa07286fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_catalog_name = \"weather\"\n",
    "silver_schema_name = \"silver\"\n",
    "silver_table_name = \"weather_measurements\"\n",
    "\n",
    "gold_catalog_name = \"weather\"\n",
    "gold_schema_name = \"gold\"\n",
    "gold_table_name = \"weather_statistics_per_day\"\n",
    "\n",
    "gold_volume_name = \"checkpoints\"\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {gold_catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {gold_catalog_name}.{gold_schema_name}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {gold_catalog_name}.{gold_schema_name}.{gold_volume_name}\")\n",
    "checkpoint_dir = f\"/Volumes/{gold_catalog_name}/{gold_schema_name}/{gold_volume_name}/{gold_table_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d980c2e-ed8d-4090-9972-27974c93b3c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_df = spark.readStream \\\n",
    "  .format(\"delta\") \\\n",
    "  .table(f\"{silver_catalog_name}.{silver_schema_name}.{silver_table_name}\")\n",
    "\n",
    "aggregation_df = source_df \\\n",
    "    .withWatermark(\"last_updated_timestamp\", \"1 hour\") \\\n",
    "    .groupBy(\n",
    "        window(\"last_updated_timestamp\", \"1 day\"),\n",
    "        \"country\",\n",
    "        \"region\",\n",
    "        \"district\"\n",
    "    ) \\\n",
    "    .agg(\n",
    "        F.min(\"temp_c\").alias(\"min_temperature\"),\n",
    "        F.max(\"temp_c\").alias(\"max_temperature\"),\n",
    "        F.avg(\"temp_c\").alias(\"avg_temperature\"),\n",
    "        F.min(\"pressure_mb\").alias(\"min_pressure\"),\n",
    "        F.max(\"pressure_mb\").alias(\"max_pressure\"),\n",
    "        F.avg(\"pressure_mb\").alias(\"avg_pressure\")\n",
    "    ) \\\n",
    "    .withColumn(\"window_start\", col(\"window.start\")) \\\n",
    "    .withColumn(\"window_end\", col(\"window.end\")) \\\n",
    "    .drop(\"window\")\n",
    "\n",
    "aggregation_df = aggregation_df.select(\n",
    "    \"country\", \"region\", \"district\", \"window_start\", \"window_end\",\n",
    "    \"min_temperature\", \"max_temperature\", \"avg_temperature\",\n",
    "    \"min_pressure\", \"max_pressure\", \"avg_pressure\"\n",
    ")\n",
    "\n",
    "writer = aggregation_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_dir) \\\n",
    "    .trigger(once=True) \\\n",
    "    .partitionBy(\"country\") \\\n",
    "    .toTable(f\"{gold_catalog_name}.{gold_schema_name}.{gold_table_name}\")\n",
    "\n",
    "writer.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_weather_data_batch_streaming_pipeline_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
